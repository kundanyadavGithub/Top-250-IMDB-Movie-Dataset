# -*- coding: utf-8 -*-
"""web_scraping_top250_Movies_IMBD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GwWca9Fa9AszdMDzI2rjB8P4NNNrxXzM
"""

from bs4 import BeautifulSoup # library to perform web scraping
import requests               # reuqest library to target a particular URL
import html5lib

"""# Scrap IMBD top 250 Movies"""

url = "https://www.imdb.com/chart/top/"

response = requests.get(url)
print(response)               # valid response, if response is 200 means it is a valid response

imdb = BeautifulSoup(response.content,'html5lib') # prasing options = 'lxml'
print(imdb)

"""### find(tag,attrs)
### it is used to fetch the first tag with the corresponding attributes
"""

r1 = imdb.find('td',attrs={'class':'titleColumn'})
print(r1)

print(r1.a)
print(r1.a.text)         # movie name
print(r1.a.get('title')) # director and crew members
print(r1.a.get('href'))  # href
print(r1.span.text[1:-1]) # release year

print(r1.text)

print(r1.text.strip()[:3])  # to know the rank of the movie

r2 = imdb.find('td',attrs={'class':'ratingColumn imdbRating'})
print(r2)

print(r2.text)

print(r2.strong.text)

print(r2.strong.get('title'))

print(r2.strong.get('title')[13:22]) # no. of users rating

movie_names = []
crew = []
rel_year = []
rank = []

for i in imdb.findAll('td',attrs={'class':'titleColumn'}):
   movie_names.append(i.a.text)
   crew.append(i.a.get('title'))
   rel_year.append(i.span.text[1:-1])
   rank.append(i.text.strip()[:3])

print(len(movie_names))
print(len(crew))
print(len(rel_year))
print(len(rank))

print(movie_names)
print(crew)
print(rel_year)
print(rank)

print(rank)

"""### Now I will use list comprehension and replace function to remove the ".\n" for rank 1 to 9 and from 9 onwords "."
"""

rank1 = [i.replace('.\n','') for i in rank]
rank2 = [i.replace('.','') for i in rank1]
print(rank2)

ratings = []
user_reviews = []

for i in imdb.findAll('td',attrs={'class':'ratingColumn imdbRating'}):
  ratings.append(i.text.strip())
  user_reviews.append(i.strong.get('title')[13:22])

print(len(ratings))
print(len(user_reviews))

print(ratings)

print(user_reviews)

"""### To get rid off , _u and u in between the user reviews values again i will use list comprehension with replace function"""

user_rev = [i.replace(',','') for i in user_reviews]

print(user_rev)

"""### Look commas are removed"""

user_rev1 = [i.replace('us','') for i in user_rev]
user_rev2 = [i.replace(' u','') for i in user_rev1]
print(user_rev2)

"""### Now, I will store this entire data into a DataFrame and for this I will use pandas"""

import pandas as pd

top250 = pd.DataFrame({'Rank':rank2,'Movie':movie_names,'Year':rel_year,
                      'Crew':crew,'IMDB Ratings':ratings,'User Reviews':user_rev2})
top250.head()

"""### Save this DataFrame into a .csv file"""

top250.to_csv('IMDB_top250_movies_Data.csv')

"""### NOW, let's perform EDA on this Dataset"""

import matplotlib.pyplot as plt
import seaborn as sns

top250.dtypes

"""### As, we see that column names Rank, Year, IMDB Ratings and User reviews are of object type so we will change this into int type"""

top250['IMDB Ratings'] = top250['IMDB Ratings'].astype('float')  # float conversion
top250['User Reviews'] = top250['User Reviews'].astype('int')    #  int conversion
top250['Year'] = top250['Year'].astype('int')                    #  int conversion
top250['Rank'] = top250['Rank'].astype('int')                    #  int conversion
top250.dtypes

"""### Plot top 7 movies with the highest number of user reviews on a bar chart"""

print(top250.columns)

top7 = top250.sort_values(by='User Reviews',ascending=False).reset_index(drop=True).head(7)
top7[["Movie","User Reviews"]]

plt.bar(top7["Movie"],top7["User Reviews"])
plt.title("Top 7 movies with the highest number of user reviews")
plt.xlabel("Movie Name")
plt.ylabel("Number of user reviews")
plt.xticks(rotation=90)
plt.show()

"""### Create a year bin with windows of 10 year gap"""

print(top250["Year"].min())    # oldest movie
print(top250["Year"].max())    # latest movie

top250["Year_bin"] = pd.cut(top250["Year"],bins=list(range(1920,2025,10)))
top250.head()

# cut() function is part of the pandas library and is used to segment and
# categorize data into bins. It is primarily used for creating discrete
# intervals or bins from continuous numerical data.

top250["Year_bin"].value_counts()

"""### for the decade 2000-2010 most number of movies(i.e 48) are in the top 250 IMDB ratings

### Compare Avg ratings for movies released on or before 2000 and movies release after 2000. Plot the reslut on a bar chart
"""

before_2000 = top250[top250["Year"]<=2000]
after_2000 = top250[top250["Year"]>2000]
print(before_2000.shape)
print(after_2000.shape)

Avg_rating = {"Before 2000":before_2000["IMDB Ratings"].mean(),
              "After 2000":after_2000["IMDB Ratings"].mean()}
Avg_rating

plt.barh(list(Avg_rating.keys()),list(Avg_rating.values()))
plt.title("Avg rating before and after 2000")
plt.show()

"""### Plot year_bin(Decade) wise avg rating of movies and depict the result on a bar chart"""

r = top250.groupby(["Year_bin"])["IMDB Ratings"].mean()
r

print(type(r))

r.plot(kind="barh")
plt.title("Decade wise Avg IMDB Ratings ")
plt.xlabel("Avg IMDB Rating")
plt.grid()
plt.show()